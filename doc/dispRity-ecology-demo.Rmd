---
title: "dispRity ecology demo"
author: "Thomas Guillerme"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: References.bib
bst: sysbio.bst
vignette: >
  %\VignetteIndexEntry{dispRity ecology demo}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

This demo aims to give quick overview of the `dispRity` package (v.0.2) for ecological analysis.
Please refer to [GitHub page](https://github.com/TGuillerme/dispRity) for other vignettes, namely the `dispRity` manual that explains the functions in more details.

To keep it short, this package allows the use of all of the dimensions of ordinated matrices (i.e. PCA, MDS, PCO) for statistical analysis rather than just a sub-set of dimensions.
For example, one might want to know whether a specific kind of water treatment at certain water depth alters invertebrate communities and composition in natural habitats.

Before starting
===============

Installing `dispRity` 
-----------------------------------

You can install this package easily if you are using the latest version of `R` (> 3.0.0) and `devtools`.

```{r, eval = FALSE}
if(!require(devtools)) install.packages("devtools")
install_github("TGuillerme/dispRity", ref = "release")
library(dispRity)
```

Data
----

For this example with ecological data we are going to use data from McClean (unpubl.).
This data is the ordination of a distance matrix based on nutrient enrichment and depth and freshwater benthic invertebrates.

```{r}
## Loading demo and the package data
library(dispRity)

## Setting the random seed for repeatability
set.seed(123)

## Loading the data
data(McClean_data)

## This dataset contains an ordinated matrix (20 dimensions) of the distance
## between 40 experimental plots.
ord_matrix <- McClean_data$ordination

## As well as two list of different factors affecting each experimental plot:
## the treatment and the depth.
treatments <- McClean_data$treatment
depth <- McClean_data$depth
```

A classical two dimensional approach
====================================

A classical way to represent this ordinated data will be to use two dimensional plots.

```{r}
## The x and y axis represent the two first dimensions (i.e. principal
## components) of the ordination
x <- ord_matrix[, 1]
y <- ord_matrix[, 2]
## The colors will represent the treatments
cols <- sub("a", "red", treatments)
cols <- sub("b", "blue", cols)
## The symbols will represent the depth
pchs <- sub(1, 16, depth)
pchs <- as.numeric(sub(2, 17, pchs))

## Graphical option
par(bty = "n")
## A classic 2D ordination plot
plot(x, y, col = cols, pch = pchs, xlab = "PC 1", ylab = "PC 2",
    xlim = range(x) + c(0, 100))
```

![image](figure/minimal-PCAplot-1){width=".8\linewidth"}

This shows the distribution of the experimental plots along the two first axis of variance of the ordinated distance matrix (i.e. the first two dimensions).
At a first glance, it seems difficult to see a clear effect from the treatments (blue or red) or the depth (rounds or triangles) since the different experimental plots with the same parameters don’t seem to cluster.
However, the problem, is that this plot ignores the 18 other dimensions of the ordination!
Additionally, these two represented dimensions do not represent a biological reality *per se*; i.e. the values on the first dimension do not represent some continuous traits (e.g. depth) but just the ordinations of correlations between the data and some factors.

Therefore, one might want to approach this problem without getting stuck in only two dimensions and consider the whole dataset as a *n*-dimensional object.

A multidimensional approach with `dispRity` 
=========================================================

Splitting the data
------------------

The first step in such analysis will be to create different series that are two sub-samples of the ordinated space (i.e. the *n*-dimensional object).
Each of these series contain a certain number of elements (i.e. the 40 experimental field plots) that have some attributes in common.
In our example, we are going to group the elements according to their depth and treatment.

```{r}
## Creating the table that contain the elements and their attributes
factors <- as.data.frame(matrix(data = c(treatments, depth), nrow = nrow(ord_matrix),
    ncol = 2, byrow = FALSE, dimnames = list(rownames(ord_matrix))))
names(factors) <- c("Treat", "Depth")
head(factors)
```

Second, let’s split the data according to these factors to create the series of the ordinated space by using the `cust.series` function:

```{r}
## Splitting the ordinated space into four subsamples
customised_series <- cust.series(ord_matrix, factors)

## Note that the output of dispRity functions are dispRity objects
class(customised_series)
## These objects are automatically printed in a summary method (calling S3 print.dispRity)
## giving information about the object
customised_series
```

For more details on the `dispRity` objects, see the [`dispRity` manual](https://github.com/TGuillerme/dispRity/blob/master/doc/dispRity-manual.pdf).
Basically the idea is to avoid jamming the `R` console such as when using:

```{r}
## Summarising the object
str(customised_series)

## Displaying the full object
print(customised_series, all = TRUE)
```

Calculating disparity
---------------------

Disparity can be calculated in many ways, and therefore, the `dispRity` function allows to measure disparity *as defined by the user*.
For more details on measuring disparity, see the [`dispRity` metric vignette](https://github.com/TGuillerme/dispRity/blob/master/doc/dispRity-metrics.Rmd).

In this example, we are going to define disparity as the median distance between the different experimental plots and the centroid of the ordinated space.
High values of disparity will indicate a general high dispersal from this centroid (i.e. on average, the experimental plots are far apart in the ordinated space).
We can define the metrics easily in the `dispRity` function by feeding them to the `metric` argument.
Here we are going to feed the functions `stats::median` and `dispRity::centroids` which calculates distances between elements and
centroid.

```{r}
## Calculating disparity
disparity <- dispRity(customised_series, metric = c(median, centroids))

## Note that disparity is a dispRity object and printing it just gives details
## on the object, not the results. We need to use summary.dispRity (S3) to get
## the results.
disparity
summary(disparity)
```

Bootstrapping the data
----------------------

One might also want to bootstrap the data to test the robustness of the measured disparity to outliers.
Also, as we can see, each series has different numbers of elements.
It might be interesting to rarefy the data as well to have only series with the same number of elements.
Both steps are easily doable through the `boot.matrix` function.

```{r}
## Simple bootstrapping (100 times)
bootstrapped_data <- boot.matrix(customised_series, bootstraps = 100)

## Bootstrapping with rarefaction (i.e. only re-sampling 17 elements each time)
rarefied_data <- boot.matrix(customised_series, bootstraps = 100,
    rarefaction = 17)

## Note that the output is a dispRity object giving some details on the series
## and the bootstraps
bootstrapped_data
rarefied_data
```

We can now rerun a more robust disparity analysis using the bootstrapped data:

```{r}
## Bootstrapped disparity
disparity_BS <- dispRity(bootstrapped_data, metric = c(median, centroids))

## Rarefied disparity
disparity_rare <- dispRity(rarefied_data, metric = c(median, centroids))
```

Summarising the data
--------------------

We can now summarise the data using various options such as the confidence intervals levels and the central tendency.

```{r}
## Summarising disparity (default)
summary(disparity_BS)

## The quantiles are calculated as 50 and 95 and the central tendency is the
## mean by default but we can specify different options
summary(disparity_BS, quantile = 90, cent.tend = median)

## Finally we can see the results of the rarefaction analysis:
summary(disparity_rare)

## Note that for the first three series, there is no observed disparity since
## the data was rarefied for these series.
```

We can also plot the results and have a look at the effect of the number of experimental plots:

```{r}
## Graphical options
quartz(width = 10, height = 5) ; par(mfrow = (c(1,2)), bty = "n")

## Plotting the bootstrapped disparity
plot(disparity_BS, main = "Bootstrapped data")

## Plotting the rarefied disparity
plot(disparity_rare, main = "Rarefied data")
```

![image](figure/minimal-rare_plots-1){width="1\linewidth"}

As we can see, there seems to be no strong effect of the number of experimental plots in each series (i.e. the rarefied plot is really similar to the bootstrapped plot) which is a good thing!

Testing the hypothesis
----------------------

Finally, we can test our hypothesis (whether the sort of water treatment at certain depth alters invertebrate communities and composition in natural habitats) by using the `test.dispRity` function.

```{r}
## Testing the effect of our factors on the bootstrapped data
summary(test.dispRity(disparity_BS, test = aov, comparisons = "all"))

## Testing the effect of our factors on the rarefied data
summary(test.dispRity(disparity_rare, test = aov, comparisons = "all"))

## Post-hoc testing of the effect of the two different factors
## Note that the comparison contains the list of the pairs of series to compare
test.dispRity(disparity_BS, test = wilcox.test,
    comparisons = list(c(1,2), c(3,4)))

## Testing the effect of the two different factors for the rarefied data
test.dispRity(disparity_rare, test = wilcox.test,
    comparisons = list(c(1,2), c(3,4)))
```

As we can see, there is strong support for an effect of the treatment and the depth on the median distance between each experimental plots and the centroid of the ordinated space.
In other words, it seems that with the second treatment and the second level of depth, the invertebrate communities and composition were further apart (i.e. more dispersed in the ordinated space) than with the first treatment and the first level of depth.
